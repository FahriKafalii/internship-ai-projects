import os
from dotenv import load_dotenv
from pathlib import Path
import streamlit as st

# Gerekli kÃ¼tÃ¼phaneleri import et
try:
    from PyPDF2 import PdfReader
    from langchain.text_splitter import CharacterTextSplitter
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_openai import ChatOpenAI
    from langchain.chains import ConversationalRetrievalChain
except ImportError as e:
    st.error(f"Gerekli bir kÃ¼tÃ¼phane eksik: {e}. LÃ¼tfen 'py311env' ortamÄ±nÄ±zÄ± kontrol edin.")
    st.stop()

# --- 1. Ortam DeÄŸiÅŸkenlerini YÃ¼kle ve Kontrol Et ---
script_dir = Path(__file__).parent
dotenv_path = script_dir / ".env"
load_dotenv(dotenv_path=dotenv_path)

LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_MODEL = os.getenv("LLM_MODEL")
LLM_ENDPOINT = os.getenv("LLM_ENDPOINT")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")

# --- Streamlit ArayÃ¼zÃ¼ ---
st.set_page_config(page_title="Basit RAG Chatbot", page_icon="ğŸ“„")
st.title("ğŸ“„ Basit PDF Chatbot (Sadece LangChain + FAISS)")

if not LLM_API_KEY:
    st.error("âŒ HATA: LLM_API_KEY bulunamadÄ±! LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    st.stop()

# --- YardÄ±mcÄ± Fonksiyonlar ---
@st.cache_resource(show_spinner="PDF okunuyor ve vektÃ¶rler oluÅŸturuluyor...")
def process_pdf(pdf_file):
    try:
        # Metni al
        raw_text = ""
        pdf_reader = PdfReader(pdf_file)
        for page in pdf_reader.pages:
            content = page.extract_text()
            if content:
                raw_text += content
        
        # ParÃ§alara ayÄ±r
        splitter = CharacterTextSplitter(separator="\n", chunk_size=1000, chunk_overlap=200)
        chunks = splitter.split_text(raw_text)
        
        # VektÃ¶r veritabanÄ±nÄ± oluÅŸtur
        embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
        vectorstore = FAISS.from_texts(chunks, embeddings)
        return vectorstore
    except Exception as e:
        st.error(f"PDF iÅŸlenirken hata oluÅŸtu: {e}")
        return None

# --- Ana Uygulama MantÄ±ÄŸÄ± ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

pdf_file = st.file_uploader("Bir PDF yÃ¼kleyin:", type=["pdf"])

if pdf_file:
    vectorstore = process_pdf(pdf_file)
    if vectorstore:
        st.success("âœ… PDF baÅŸarÄ±yla iÅŸlendi. Åimdi soru sorabilirsiniz.")
        
        # Sohbet zincirini oluÅŸtur
        llm = ChatOpenAI(model=LLM_MODEL, openai_api_key=LLM_API_KEY, base_url=LLM_ENDPOINT)
        st.session_state.conversation_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=vectorstore.as_retriever()
        )
        # Yeni PDF yÃ¼klendiÄŸinde sohbet geÃ§miÅŸini temizle
        st.session_state.chat_history = []

# Sohbet geÃ§miÅŸini ekranda gÃ¶ster
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# KullanÄ±cÄ±dan soru al
user_question = st.chat_input("â“ PDF hakkÄ±nda bir soru sorun...")

if user_question:
    if "conversation_chain" in st.session_state:
        try:
            with st.spinner("Cevap oluÅŸturuluyor..."):
                result = st.session_state.conversation_chain({
                    "question": user_question,
                    "chat_history": st.session_state.chat_history
                })
                response = result["answer"]

                # Sohbet geÃ§miÅŸini gÃ¼ncelle
                st.session_state.chat_history.append({"role": "user", "content": user_question})
                st.session_state.chat_history.append({"role": "assistant", "content": response})

                # SayfayÄ± yeniden Ã§izerek yeni mesajlarÄ± gÃ¶ster
                st.rerun()

        except Exception as e:
            st.error(f"Soru iÅŸlenirken bir hata oluÅŸtu: {e}")
            st.warning("API anahtarÄ±nÄ±zÄ± (kredi/geÃ§erlilik) veya internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")
    else:
        st.warning("LÃ¼tfen Ã¶nce bir PDF dosyasÄ± yÃ¼kleyin.")